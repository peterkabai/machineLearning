{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YYTrI3ShX6O"
   },
   "source": [
    "# RNN for Text Generation\n",
    "**Peter Kabai**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hrzwcBuqZy6"
   },
   "source": [
    "## Part 1 - Replicating Karpathy's Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jqy6gp1chn1Q"
   },
   "source": [
    "### Introduction\n",
    "This project aims to replicate Karpathy's text generation code in TensorFlow using an RNN. The text that will be used is Alice in Wonderland by Lewis Carroll. To mimic the Karpathy code, each iteration will print text that's 200 characters long, and each input sequence will be 25 characters long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk8iW6isp2Oa"
   },
   "source": [
    "### Enabling the GPU\n",
    "Here the Colab GPU is enabled. It may not help for this particular RNN, but enabling it can't hurt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RuJ2bU0Epw71",
    "outputId": "8f920614-22d6-4e50-d612-06c6c184e45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "    print('Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckFUek3Ip441"
   },
   "source": [
    "### Importing Alice in Wonderland\n",
    "Next we import the text file we will be using. In this case, it's Alice in Wonderland. The text file is imported, and the first 225 characters are printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "L26KLhkkkphB",
    "outputId": "f99bec3f-8abf-4226-f44c-d26c6771f371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿\n",
      "ALICE'S ADVENTURES IN WONDERLAND\n",
      "\n",
      "Lewis Carroll\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://raw.githubusercontent.com/peterkabai/tensorFlow/master/textFiles/aliceInWonderland.txt\"\n",
    "data = requests.get(url).text\n",
    "print(data[:225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVoHTp-9GDZ4"
   },
   "source": [
    "Next, the total number of characters and the number of unique characters is printed below. The number of unique characters is 71. When one-hot encoding is done later on, each character will be replaced by an array of 70 zeros and 1 one, so that the character indices are treated as categoricaal rather than numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hGeLSj7sGCrk",
    "outputId": "dba474de-0f6b-4259-a117-0229ef09888a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has 147731 total characters and 71 unique characters.\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('The text has %d total characters and %d unique characters.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTCAAUTcOZh"
   },
   "source": [
    "### Sampling Sequences\n",
    "Below, the Alice in Wonderland text is used to generate sequences of characters and sequences of characters shifted over one. X will contain the input sequence, and y will contain the sequence shifted over one character. This input sequence is actually the index of the character, rather than the character itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zc7tFeBSjVq9"
   },
   "outputs": [],
   "source": [
    "# the number of sequential characters to sample\n",
    "length_of_input = 25\n",
    "\n",
    "# maps each character to a number and each number to a character\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# create training sequences and corresponding labels\n",
    "import numpy as np\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(data)-length_of_input-1, 1):\n",
    "    X.append([char_to_ix[ch] for ch in data[i:i+length_of_input]])\n",
    "    y.append([char_to_ix[ch] for ch in data[i+1:i+length_of_input+1]])\n",
    "\n",
    "# reshapes the data\n",
    "X_modified = np.reshape(X, (len(X), length_of_input))\n",
    "y_modified = np.reshape(y, (len(y), length_of_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MH4BEv-gdYvs"
   },
   "source": [
    "This function below will help print the array of character indices as characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ioy_zKOTRrz2"
   },
   "outputs": [],
   "source": [
    "# function to front the characters that match an array of indices\n",
    "def print_chars(indexArray):\n",
    "    print(\"---------------------------------------------\")\n",
    "    string = \"\"\n",
    "    for c in indexArray:\n",
    "        if (c != None):\n",
    "            string += ix_to_char.get(c)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q287ZJkYc48Q"
   },
   "source": [
    "### Graph Setup\n",
    "Here the TensorFlow graph is created. To mimic the Karpathy code, the iterations (number of characters to generate per epoch) is set to 200. The length of the character sequences has already been set to 25 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "agiXJvzZS-JD",
    "outputId": "2602fdff-78eb-4eb1-ad29-d80356df9d7d"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sets hyperparameters to mimic the Karpathy code\n",
    "n_neurons = 50\n",
    "num_batches = 5\n",
    "iterations = 200\n",
    "n_layers = 1\n",
    "learning_rate = 0.005\n",
    "sequence_to_use = 0\n",
    "num_sequences = X_modified.shape[0]\n",
    "\n",
    "# X has any num of batches and chars, and vocab_size due to one-hot encoding\n",
    "X = tf.placeholder(tf.float32, [None, None, vocab_size])\n",
    "\n",
    "# y has any num of batches, and 'length_of_input' characters\n",
    "y = tf.placeholder(tf.int32, [None, length_of_input])\n",
    "\n",
    "# more TensorFlow stuff defined here\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu) for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "logits = tf.layers.dense(outputs, vocab_size)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "# tf settings that are needed in both the session and result code blocks\n",
    "saver = tf.train.Saver()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# location to save the model\n",
    "out_file = \"./models/rnnTextGen/rnnTextGen.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Only run this when re-starting the epoch count!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of epochs that have been run saves here to be restored later\n",
    "epoch_count = tf.Variable(0, name='epoch_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gXc7urmdiYW"
   },
   "source": [
    "### TensorFlow Session\n",
    "Next, all the components are brough togetherhere. Batches of 25 character sequences are appended to one another. Every time an iteration runs, a new character will be appended to the seed, and after every epoch the resulting 200 characters are printed. However, only the first 15 epochs' results are actually printed here. Below, one last epoch will be run to print out the final results. The first character of the 200 character output is picked randomly.\n",
    "\n",
    "**Note:** this will run forever, and should be stopped with a keyboard inturrupt. The code block after this one will then run one last epoch to print the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1380
    },
    "colab_type": "code",
    "id": "B-9Nv1OqS-R4",
    "outputId": "e752b95e-2141-41d7-c7c4-b50d61832311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New session started...\n",
      "---------------------------------------------\n",
      "s eineeiTw'siesohasD i thwLiulrvsa*nndrthe wreehaw dv,iFhe eeoia lldtsgDï»¿ e t weeseb re hetN sg n oodrro!X, 'tt thi;ljsoftthafitl ( aheie\n",
      "---------------------------------------------\n",
      " d rindtteedeeth w d buhe sibagC*lo]mer ,ud boutlalAle auy beat pe perles\n",
      "y foebleky, tohe wasto waad of\n",
      "---------------------------------------------\n",
      "ithen conm hcd wo angtditlin\n",
      "Indefs bfaw\n",
      "Dying,s supn she \n",
      "dwe fodlnd thagN)gughe Rur?Oled\" nced fhaulscRite houd wit focimed'r roipoul yun nulwn n., intthe bayr\n",
      "---------------------------------------------\n",
      "Yd-, thi seinctu dolndt me merag wo\n",
      "meng ti fousolr phery tos torne marl dfangtheTie, shotr thar thisas, steE'or!otoll\n",
      "hew le dout\n",
      "the he\n",
      "de'r aronwisenle laswras Rulily hl kift Hwnut the she nl wo \n",
      "---------------------------------------------\n",
      "y.u thitkeeehas megs To Lrake I ticn\n",
      "a shoe yoc NeSn und-\n",
      "there berey fe Nhithata\n",
      "aryrllm yat cetPy ag anatrathing(o dats-emekenfs ga\n",
      "s momls tou\n",
      "caete?' icaist bag 'e wal\n",
      "---------------------------------------------\n",
      "[ghiad he.  and ahink Se dicnd arley\n",
      "'MAsld bot he  hat an we.. la, nowDe eusd win sall ollpe it' in yin rut, yitkakneiths\n",
      "hldt Aurte ohen, tercag wling th ald loct\n",
      "che lot a fe rarer, and All beVe\n",
      "\n",
      "---------------------------------------------\n",
      "NS booy lemed itn\n",
      ", ard, iy addeng lotleee ther, us wouthichel (ton gowle tof wolk was saTe'ver, on ony scemind tome, giluced dooeete and the Don a thu las and hiceI beFin aowe cof 'r, oaud out shta. \n",
      "---------------------------------------------\n",
      "egtnrit; drifhd-ver't, dArver fould no thi cand roup wrrke! fele,  talee\n",
      "re!\n",
      "hars ay upin the coop the gh sitt Itereengabas so tpe nad\n",
      "hap, boote bole oow nou it Aou foullllr lick hoind's\n",
      "ing vero'';\n",
      "---------------------------------------------\n",
      "Y ase cas alline' tere natly fhole u and d untteCCy hit thulsherthedd\n",
      ", nnced wariY, \n",
      "sourVo itof, .er h   ; t   t  o h  b f.\n",
      "ar, eotig re, . Y t\n",
      "a\n",
      "---------------------------------------------\n",
      "thes  nt the nh licilind riitt tishasthustA hatteT thr methh gury ,or thetld T nde\n",
      "boI  lafk so Fohy rnoind lige bong, cor b'w\n",
      "the gotad-o ole d\n",
      "do\n",
      " af atanding foulg rtt hotsd on hurd; 'ler\n",
      "flrbm\n",
      "---------------------------------------------\n",
      "' hound ew out ofs ar\n",
      ", sherhen wh\n",
      "le as Y, selike,'ring, be ousse seb, bednowherdeve oneel tout felv thid nlth\n",
      "it wos mouge of nowomlit verarsibh\n",
      "'Dow oule so  demumat aboe (of  W: ghre wardd up i\n",
      "---------------------------------------------\n",
      "! wai it maicheren\n",
      "imnit inx\n",
      "mor (soweqAugha\n",
      "gely waa\n",
      "her the lerfh she paisi cht ithe, they sank inmprenxtes: 'ad eape in anly yon she the wa foup\n",
      "G   *e bry qris the soushed Fo  I gard  Tit onof\n",
      "---------------------------------------------\n",
      "f oid she ther Iz teise\n",
      "boigt si wand ing atoWhalsard wnuy sefpeat seike ' stof fon and the hanNzy wost of adelco to  ferses myrt, selliat! so cet, JevemF s iscg Tre-* *I)    'C Itd IOo ren grad now h\n",
      "---------------------------------------------\n",
      "l hers      itt\n",
      "of  st Ald ARl its ly!\n",
      " w sisay bow so ad totrked seTcard ii so thuEed noul-Y I\n",
      "\n",
      "Ring the sousacring wars, a ha walice a  ceghe thee WoE\n",
      " uppiad wtr in\n",
      "P neeteTche crid thinld det\n",
      "---------------------------------------------\n",
      "whs nits!'r in her 'Gou. san strertingrRV. * chg\n",
      "Sis het Ally cand toes fHown'tr the semy tas toy; Oh hedn sist, shed hes thei he thon 'wa  Whingay you to\n",
      "littlice besw'bbi she , Ie!' wh p thing, fle\n",
      "---------------------------------------------\n",
      "be To, on sit reller, if a  po and besHg har:\n",
      "notss alles wel wangl sey red, puen time s, aying itp trs.t),  ver versf sre and so, kno-tap \" and hen sappis she all ruon! of lowr thend is I snon, mucr:\n",
      "---------------------------------------------\n",
      "and dtong the Whe\n",
      "thay tald, sher.\n",
      "'  'on she ates foes: to any Doer\n",
      "dom\n",
      " teailisprinpdasth caatl I's sherd thaig\n",
      "And toTveve? the le mip I''\n",
      "to mwn shime wein,\n",
      "tem witheld that nove an, tine th\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "iterations_to_print = 30\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # attempts to restore the saved session if avaliable\n",
    "    tf.initialize_all_variables().run()\n",
    "    try:\n",
    "        saver.restore(sess, out_file)\n",
    "        print(\"Session with\", epoch_count.eval(), \"epochs was restored...\")\n",
    "    except:\n",
    "        init.run()\n",
    "        print(\"New session started...\")\n",
    "        \n",
    "    # epoch loop starts here\n",
    "    while (True):\n",
    "        \n",
    "        # this helps extra prediction when they won't be printed anyway\n",
    "        if (epoch_count.eval() < iterations_to_print):\n",
    "            \n",
    "            # creates a seed to start the string from\n",
    "            pred_indices = [random.randint(0,vocab_size)]\n",
    "            \n",
    "            # each iteration is one new character\n",
    "            for iteraton in range(0, iterations):\n",
    "                \n",
    "                # creates batches, each row is an array of sequential characters\n",
    "                in_indices = []\n",
    "                out_indices = []\n",
    "                for batch in range(0, num_batches):\n",
    "                \n",
    "                    # if we run out of sequences, the sequence to use returns to 0\n",
    "                    if (sequence_to_use >= num_sequences):\n",
    "                        sequence_to_use = 0\n",
    "                        \n",
    "                    # in and out indices are appended to\n",
    "                    # 'sequence_to_use' is incrimented to get the next sequence when re-run\n",
    "                    in_indices.append(X_modified[sequence_to_use])\n",
    "                    out_indices.append(y_modified[sequence_to_use])\n",
    "                    sequence_to_use += 1\n",
    "                \n",
    "                # one hot encode the inputs (the outputs do not need encoding)\n",
    "                X_encoded = tf.one_hot(np.asarray(in_indices), vocab_size).eval()\n",
    "                \n",
    "                # run the trainining op\n",
    "                sess.run(training_op, feed_dict={X: np.asarray(X_encoded), y: np.asarray(out_indices)})\n",
    "            \n",
    "                # this helps extra prediction when they won't be printed anyway\n",
    "                if (epoch_count.eval() < iterations_to_print):\n",
    "                \n",
    "                    # one hot encode the prediction indices\n",
    "                    pred_encoded = tf.one_hot(np.asarray(pred_indices), vocab_size).eval()\n",
    "                \n",
    "                    # get predictions as probabilities\n",
    "                    predictions = sess.run(probs, feed_dict={X: np.asarray([pred_encoded])})\n",
    "                \n",
    "                    # take the probabilities from the last character\n",
    "                    # pick the next index using the probabilities\n",
    "                    ix = np.random.choice(range(vocab_size), p=(predictions[0][-1]).ravel())\n",
    "                \n",
    "                    # add to the array of indices\n",
    "                    pred_indices.append(ix)\n",
    "            \n",
    "        # print the string every epoch for the first 'iterations_to_print' epochs\n",
    "        if (epoch_count.eval() < iterations_to_print):\n",
    "            print_chars(pred_indices)\n",
    "            \n",
    "        # increment the epoch count used to see when to print the results\n",
    "        epoch_count = epoch_count + 1\n",
    "    \n",
    "        # save the session\n",
    "        save_path = saver.save(sess, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF3lflBtof08"
   },
   "source": [
    "### Results\n",
    "Since the results from all epochs were not all printed above, one last epoch is run below to print out the final result after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOGyXxMInkqI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session was restored...\n",
      "---------------------------------------------\n",
      "t dHP.qfH(baE.OBq.aq:.mC?-:b qkHP .?fP.R(bt.Mb_[ RcCBbTHPe?[ kcoPOmfC ?.Mq :LW .k.BOe,_ eXLii aH.[ mS.R\n",
      "tt(q(f at.:?l  ft-OVe TE[ te .?CjYe t\n",
      "OLbinuofMqm\n",
      "\n",
      "?inpLbut  eftLOtqikfw lhoArMH. oin oM[?fii\n"
     ]
    }
   ],
   "source": [
    "# for useful comments see code block above\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        saver.restore(sess, out_file)\n",
    "        print(\"Session was restored...\")\n",
    "    except:\n",
    "        print(\"Session failed to be restored...\")\n",
    "        import sys\n",
    "        sys.exit()\n",
    "        \n",
    "    pred_indices = [random.randint(0,vocab_size)]\n",
    "    for iteraton in range(0, iterations):\n",
    "        in_indices = []\n",
    "        out_indices = []\n",
    "        for batch in range(0, num_batches):\n",
    "            if (sequence_to_use > num_sequences):\n",
    "                sequence_to_use = 0\n",
    "            in_indices.append(X_modified[sequence_to_use])\n",
    "            out_indices.append(y_modified[sequence_to_use])\n",
    "            sequence_to_use += 1\n",
    "        X_encoded = tf.one_hot(np.asarray(in_indices), vocab_size).eval()\n",
    "        sess.run(training_op, feed_dict={X: np.asarray(X_encoded), y: np.asarray(out_indices)})\n",
    "        pred_encoded = tf.one_hot(np.asarray(pred_indices), vocab_size).eval()\n",
    "        predictions = sess.run(probs, feed_dict={X: np.asarray([pred_encoded])})\n",
    "        ix = np.random.choice(range(vocab_size), p=(predictions[0][-1]).ravel())\n",
    "        pred_indices.append(ix)\n",
    "    print_chars(pred_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oAoGr_Uvq0me"
   },
   "source": [
    "## Part 2 - Further Exploration with Harry Potter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER ONE \n",
      "THE BOY WHO LIVED \n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. \n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/peterkabai/tensorFlow/master/textFiles/harryPotter.txt\"\n",
    "data = requests.get(url).text\n",
    "print(data[:298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
